{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return np.linalg.norm(vec1-vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(vec1, vec2):\n",
    "    vector_abs = np.abs(vec1-vec2)\n",
    "    return np.sum(vector_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_generalization_error(predicted, actual):\n",
    "    accuracy = np.sum(predicted == actual)\n",
    "    return accuracy/len(actual), 1-(accuracy/len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true_pos, false_pos):\n",
    "    return true_pos/(true_pos + false_pos)\n",
    "\n",
    "def recall(true_pos, false_neg):\n",
    "    return true_pos/(true_pos+false_neg)\n",
    "\n",
    "def f1_score(prec, rec):\n",
    "    return 2*((prec*rec)/(prec+rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predicted, actual):\n",
    "    tn = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for i in range(0, len(predicted)):\n",
    "        if predicted[i] == actual[i] and actual[i] == 0:\n",
    "            tn += 1\n",
    "        elif predicted[i] == actual[i] and actual[i] == 1:\n",
    "            tp += 1\n",
    "        elif predicted[i] != actual[i] and actual[i] == 0:\n",
    "            fp += 1\n",
    "        elif predicted[i] != actual[i] and actual[i] == 1:\n",
    "            fn += 1\n",
    "            \n",
    "    return np.array([[tn, fp],[fn, tp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def roc_curve(true_classes, class_probabilities):\n",
    "    \"\"\"Given true classes and class probabilities calculates fpr and tpr values and returns them as lists that can be used to construct a ROC curve\"\"\"\n",
    "    true_classes, class_probabilities = np.asarray(true_classes) , np.asarray(class_probabilities)\n",
    "    tpr_values=[]\n",
    "    fpr_values=[]\n",
    "    for threshold in range(100):\n",
    "        predicted_classes=(class_probabilities > float(threshold/100.)).astype(int)\n",
    "        fpr=np.sum(predicted_classes[np.where(predicted_classes == 1 )]  != true_classes[np.where(predicted_classes == 1 )])/true_classes[np.where(true_classes == 0 )].shape[0]\n",
    "        tpr=np.sum(predicted_classes[np.where(predicted_classes == 1 )]  == true_classes[np.where(predicted_classes == 1 )])/true_classes[np.where(true_classes == 1 )].shape[0]\n",
    "        fpr_values.append(fpr)\n",
    "        tpr_values.append(tpr)\n",
    "    return fpr_values,tpr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(true_classes, class_probabilities):\n",
    "    '''Calculates area under the roc curve by calling the roc curve function to calculate tpr and fpr'''\n",
    "    x,y=roc_curve(true_classes, class_probabilities)\n",
    "    auc=abs(np.trapz(y,x, axis=-1))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_curve(true_classes, class_probabilities):\n",
    "    \"\"\"Given true classes and class probabilities calculates precision and recall values and returns them and the thresholds as lists that can be used to construct a PR curve\"\"\"\n",
    "    true_classes, class_probabilities = np.asarray(true_classes) , np.asarray(class_probabilities)\n",
    "    p_values=[]\n",
    "    r_values=[]\n",
    "    thresholds=[]\n",
    "    for threshold in range(100):\n",
    "        predicted_classes=(class_probabilities > float(threshold/100.)).astype(int)\n",
    "        p=np.sum(predicted_classes[np.where(predicted_classes == 1 )]  == true_classes[np.where(predicted_classes == 1 )])/predicted_classes[np.where(predicted_classes == 1 )].shape[0]\n",
    "        r=np.sum(predicted_classes[np.where(predicted_classes == 1 )]  == true_classes[np.where(predicted_classes == 1 )])/true_classes[np.where(true_classes == 1 )].shape[0]\n",
    "        p_values.append(p)\n",
    "        r_values.append(r)\n",
    "        thresholds.append(threshold)\n",
    "    return p_values,r_values, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
